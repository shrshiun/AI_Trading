{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回到 FINRL/\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Trading.src import config\n",
    "from AI_Trading.src.env_portfolio_allocation import *\n",
    "from AI_Trading.src.evaluatePortfolioPerformance import *\n",
    "from AI_Trading.src import model_config\n",
    "from AI_Trading.src.preprocess import *\n",
    "from AI_Trading.src.generatePortfolioAction import *\n",
    "from AI_Trading.src.train import *\n",
    "from AI_Trading.src.customizedEnv import *\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "model_name = 'PPO'\n",
    "exp = 'test'\n",
    "\n",
    "# create training log folder\n",
    "save_path = os.path.join(config.LOG_PATH, exp)\n",
    "if not os.path.isdir(save_path):\n",
    "     try:\n",
    "          os.mkdir(save_path)\n",
    "     except Exception:\n",
    "          print(f'no folder {save_path}')\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for i in tqdm(range(len(config.TRAIN_START_DATE))):\n",
    "    # create training log\n",
    "    training_log_path = f'{config.LOG_PATH}/{exp}/training_log_{model_name}_{i}.csv'\n",
    "    training_weight_path = f'{config.LOG_PATH}/{exp}/training_weight_{model_name}_{i}.csv'\n",
    "    training_share_path = f'{config.LOG_PATH}/{exp}/training_share_{model_name}_{i}.csv'\n",
    "    if os.path.exists(training_log_path):\n",
    "        os.remove(training_log_path)\n",
    "\n",
    "    if os.path.exists(training_weight_path):\n",
    "        os.remove(training_weight_path)\n",
    "\n",
    "    if os.path.exists(training_share_path):\n",
    "        os.remove(training_share_path)\n",
    "\n",
    "    train,trade = preprocess(config.TRAIN_START_DATE[0], config.TRAIN_END_DATE[i], config.TEST_START_DATE[i], config.TEST_END_DATE[i], window=config.ADD_WINDOW, cov=False)\n",
    "    env_kwargs = {\n",
    "        \"training_log_path\": training_log_path,\n",
    "        \"training_weight_path\": training_weight_path,\n",
    "        \"training_share_path\": training_share_path,\n",
    "        \"hmax\": 100, \n",
    "        \"initial_amount\": config.INITIAL_AMOUNT, \n",
    "        \"transaction_cost_pct\": 0.001, \n",
    "        \"state_space\": 7, \n",
    "        \"stock_dim\": len(train.tic.unique()), \n",
    "        \"tech_indicator_list\": config.INDICATORS, \n",
    "        \"action_space\": len(train.tic.unique()), \n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"add_cash\": False,\n",
    "        \"lookback\": config.LOOKBACK,\n",
    "        \"alpha\": config.REWARD_ALPHA,\n",
    "        \"add_window\": config.ADD_WINDOW,\n",
    "        \"cov\": False,\n",
    "        \"reward_type\": 'portfolioReturn'\n",
    "    }\n",
    "    print(env_kwargs)\n",
    "    print('config.add_window:', config.ADD_WINDOW)\n",
    "\n",
    "    # env_train = blackLittermanEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = blackLittermanEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "    env_train = windowEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    env_trade = windowEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    model_index = i\n",
    "    episode = 2\n",
    "    total_timesteps = len(train)/len(train.tic.unique())*episode\n",
    "    print('total timestep:', total_timesteps)\n",
    "    print(model_config.DDPG_PARAMS)\n",
    "    # load model\n",
    "    model_zip_path = f'{config.TRAINED_MODEL_PATH}/{exp}/{model_name}_{str(model_index-1)}.zip'\n",
    "    if os.path.exists(model_zip_path):\n",
    "        if model_name == 'A2C':\n",
    "            model = A2C.load(model_zip_path)\n",
    "        elif model_name == 'PPO':\n",
    "            model = PPO.load(model_zip_path,env=env_train, seed=0,force_reset=True)\n",
    "        elif model_name == 'DDPG':\n",
    "            model = DDPG.load(model_zip_path,env=env_train, seed=0,force_reset=True)\n",
    "        elif model_name == 'TD3':\n",
    "            model = TD3.load(model_zip_path)\n",
    "        elif model_name == 'SAC':\n",
    "            model = SAC.load(model_zip_path)\n",
    "        trainPortfolioAllocation(exp, env_train, model_name, model_index, continuous=True, model=model, total_timesteps=total_timesteps)\n",
    "    else:\n",
    "        trainPortfolioAllocation(exp, env_train, model_name, model_index, total_timesteps=total_timesteps)\n",
    "    #test setting\n",
    "    model_zip_path = f'{config.TRAINED_MODEL_PATH}/{exp}/{model_name}_{str(model_index)}.zip'\n",
    "    if os.path.exists(model_zip_path):\n",
    "        if model_name == 'A2C':\n",
    "            model = A2C.load(model_zip_path)\n",
    "        elif model_name == 'PPO':\n",
    "            model = PPO.load(model_zip_path, seed=0)\n",
    "        elif model_name == 'DDPG':\n",
    "            model = DDPG.load(model_zip_path, seed=0)\n",
    "        elif model_name == 'TD3':\n",
    "            model = TD3.load(model_zip_path)\n",
    "        elif model_name == 'SAC':\n",
    "            model = SAC.load(model_zip_path)\n",
    "    else:\n",
    "        print('no model')\n",
    "        break\n",
    "    save_path = os.path.join(config.RESULTS_DIR, exp)\n",
    "    if not os.path.isdir(save_path):\n",
    "     try:\n",
    "          os.mkdir(save_path)\n",
    "     except Exception:\n",
    "          print(f'no folder {save_path}')\n",
    "          pass\n",
    "    # test\n",
    "    df_daily_return, df_actions = test_portfolioAllocation(model, env_trade)\n",
    "    df_actions.to_csv(f'{save_path}/df_action_{model_name}_{model_index}.csv')\n",
    "    # evaluate\n",
    "    print(\"==============DRL Strategy Stats===========\")\n",
    "    df_return, df_portfolio_value = computeReturns(df_actions,trade, transCostRate=0.001)\n",
    "    returns, DRL_stats = getStats(df_return)\n",
    "    print(DRL_stats)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2d2e8e450be3e223dc413b7f8a28490ca56561e6968625b0b65da592ce3e9cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('FinRL': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
