{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回到 FINRL/\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Trading.src import config\n",
    "from AI_Trading.src.env_portfolio_allocation import *\n",
    "from AI_Trading.src.evaluate import *\n",
    "from AI_Trading.src import model_config\n",
    "from AI_Trading.src.preprocess import *\n",
    "from AI_Trading.src.testPortfolio import *\n",
    "from AI_Trading.src.train import *\n",
    "from AI_Trading.src.augmentation import *\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "model_name = 'DDPG'\n",
    "exp = 'DDPG_OHLC(normalized)_alpha0_3y'\n",
    "\n",
    "# create training log folder\n",
    "save_path = os.path.join(config.LOG_PATH, exp)\n",
    "if not os.path.isdir(save_path):\n",
    "     try:\n",
    "          os.mkdir(save_path)\n",
    "     except Exception:\n",
    "          print(f'no folder {save_path}')\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for i in tqdm(range(len(config.TRAIN_START_DATE))):\n",
    "    # create training log\n",
    "    training_log_path = f'{config.LOG_PATH}/{exp}/training_log_{model_name}_{i}.csv'\n",
    "    training_weight_path = f'{config.LOG_PATH}/{exp}/training_weight_{model_name}_{i}.csv'\n",
    "    training_share_path = f'{config.LOG_PATH}/{exp}/training_share_{model_name}_{i}.csv'\n",
    "    if os.path.exists(training_log_path):\n",
    "        os.remove(training_log_path)\n",
    "\n",
    "    if os.path.exists(training_weight_path):\n",
    "        os.remove(training_weight_path)\n",
    "\n",
    "    if os.path.exists(training_share_path):\n",
    "        os.remove(training_share_path)\n",
    "\n",
    "    train,trade = preprocess(config.TRAIN_START_DATE[i], config.TRAIN_END_DATE[i], config.TEST_START_DATE[i], config.TEST_END_DATE[i])\n",
    "    env_kwargs = {\n",
    "        \"training_log_path\": training_log_path,\n",
    "        \"training_weight_path\": training_weight_path,\n",
    "        \"training_share_path\": training_share_path,\n",
    "        \"hmax\": 100, \n",
    "        \"initial_amount\": config.INITIAL_AMOUNT, \n",
    "        \"transaction_cost_pct\": 0.001, \n",
    "        \"state_space\": len(train.tic.unique()), \n",
    "        \"stock_dim\": len(train.tic.unique()), \n",
    "        \"tech_indicator_list\": config.INDICATORS, \n",
    "        \"action_space\": len(train.tic.unique()), \n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"add_cash\": False,\n",
    "        \"alpha\": 0,\n",
    "        \"add_window\": 0\n",
    "    }\n",
    "    print(env_kwargs)\n",
    "    print('config.add_window:', config.ADD_WINDOW)\n",
    "    # env_train = maxPortfolioReturnEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = maxPortfolioReturnEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    env_train = riskSensitiveEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    env_trade = riskSensitiveEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = trendConcernEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = trendConcernEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "    \n",
    "    # env_train = varianceEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = varianceEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = contrarianEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = contrarianEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = downsideRiskEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = downsideRiskEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = macdConcernEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = macdConcernEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    model_index = i\n",
    "    # episode = 80\n",
    "    # total_timesteps = len(train)/len(train.tic.unique())*episode\n",
    "    total_timesteps = 10**5\n",
    "    trainPortfolioAllocation(exp, env_train, model_name, model_index,total_timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate setting\n",
    "model_name = 'DDPG'\n",
    "exp = 'DDPG_OHLC(normalized)_alpha0_3y'\n",
    "save_path = os.path.join(config.RESULTS_DIR, exp)\n",
    "training_log_path = f'{config.LOG_PATH}/{exp}/training_log_{exp}_0.csv'\n",
    "training_weight_path = f'{config.LOG_PATH}/{exp}/training_weight_{exp}_0.csv'\n",
    "training_share_path = f'{config.LOG_PATH}/{exp}/training_share_{exp}_0.csv'\n",
    "if not os.path.isdir(save_path):\n",
    "    try:\n",
    "        os.mkdir(save_path)\n",
    "    except Exception:\n",
    "        print(f'no folder {save_path}')\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annualReturn_allYear = pd.DataFrame()\n",
    "df_mdd_allYear = pd.DataFrame()\n",
    "df_sharpe_allYear = pd.DataFrame()\n",
    "df_sortino_allYear = pd.DataFrame()\n",
    "df_calmar_allYear = pd.DataFrame()\n",
    "df_annualReturn_rank_allYear = pd.DataFrame()\n",
    "df_mdd_rank_allYear = pd.DataFrame()\n",
    "df_sharpe_rank_allYear = pd.DataFrame()\n",
    "df_sortino_rank_allYear = pd.DataFrame()\n",
    "df_calmar_rank_allYear = pd.DataFrame()\n",
    "\n",
    "# evaluate\n",
    "for i in tqdm(range(len(config.TEST_START_DATE))):\n",
    "    train,trade = preprocess(config.TRAIN_START_DATE[i], config.TRAIN_END_DATE[i], config.TEST_START_DATE[i], config.TEST_END_DATE[i])\n",
    "    env_kwargs = {\n",
    "        \"training_log_path\": training_log_path,\n",
    "        \"training_weight_path\": training_weight_path,\n",
    "        \"training_share_path\": training_share_path,\n",
    "        \"hmax\": 100, \n",
    "        \"initial_amount\": config.INITIAL_AMOUNT, \n",
    "        \"transaction_cost_pct\": 0.001, \n",
    "        \"state_space\": len(train.tic.unique()), \n",
    "        \"stock_dim\": len(train.tic.unique()), \n",
    "        \"tech_indicator_list\": config.INDICATORS, \n",
    "        \"action_space\": len(train.tic.unique()), \n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"add_cash\": False,\n",
    "        \"alpha\": 0,\n",
    "        \"add_window\": 0\n",
    "    }\n",
    "    print(env_kwargs)\n",
    "    print('config.add_window:', config.ADD_WINDOW)\n",
    "    # env_train = maxPortfolioReturnEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = maxPortfolioReturnEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = trendConcernEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = trendConcernEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    env_train = riskSensitiveEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    env_trade = riskSensitiveEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = varianceEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = varianceEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = contrarianEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = contrarianEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = downsideRiskEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = downsideRiskEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "\n",
    "    # env_train = macdConcernEnv(df = train, is_test_set=False, **env_kwargs)\n",
    "    # env_trade = macdConcernEnv(df = trade, is_test_set=True, **env_kwargs)\n",
    "    model_index = i\n",
    "    \n",
    "    # load model\n",
    "    model_zip_path = f'{config.TRAINED_MODEL_PATH}/{exp}/{model_name}_{str(model_index)}.zip'\n",
    "    if model_name == 'A2C':\n",
    "        model = A2C.load(model_zip_path,seed=0)\n",
    "    elif model_name == 'PPO':\n",
    "        model = PPO.load(model_zip_path,seed=0)\n",
    "    elif model_name == 'DDPG':\n",
    "        model = DDPG.load(model_zip_path,seed=0)\n",
    "    elif model_name == 'TD3':\n",
    "        model = TD3.load(model_zip_path)\n",
    "    elif model_name == 'SAC':\n",
    "        model = SAC.load(model_zip_path)\n",
    "\n",
    "    # test\n",
    "    df_daily_return, df_actions = test_portfolioAllocation(model, env_trade)\n",
    "    df_actions.to_csv(f'{save_path}/df_action_{model_name}_{model_index}.csv')\n",
    "\n",
    "    # evaluate\n",
    "    print(\"==============DRL Strategy Stats===========\")\n",
    "    df_return, df_portfolio_value = computeReturns(df_actions,trade, transCostRate=0.001)\n",
    "    returns, DRL_stats = getStats(df_return)\n",
    "    print(DRL_stats)\n",
    "\n",
    "    print(\"==============Equal Weight Strategy Stats===========\")\n",
    "    equalWeight_actions = getEqualWeightActions(trade)\n",
    "    df_equalWeight_return, df_portfolio_value = computeReturns(equalWeight_actions,trade, transCostRate= 0.001)\n",
    "    equalWeight_returns, equalWeight_stats = getStats(df_equalWeight_return)\n",
    "    print(equalWeight_stats)\n",
    "\n",
    "    print(\"==============Min-Variance Strategy Stats===========\")\n",
    "    # minVariance_actions = getMinVarianceActions(trade)\n",
    "    # df_minVariance_return, df_minVariance_portfolio_value = computeReturns(minVariance_actions,trade, transCostRate=0.001)\n",
    "    # minVariance_returns, minVariance_stats = getStats(df_minVariance_return)\n",
    "    # print(minVariance_stats)\n",
    "\n",
    "    print(\"==============All In Stock Strategy Stats===========\")\n",
    "    all_stock_actions= getTicActions(trade, 'VTI')\n",
    "    df_stock_return, df_stock_value = computeReturns(all_stock_actions,trade, transCostRate= 0.001)\n",
    "    stock_returns, stock_stats = getStats(df_stock_return)\n",
    "    print(stock_stats)\n",
    "\n",
    "    print(\"==============All In Debt Strategy Stats===========\")\n",
    "    all_debt_actions= getTicActions(trade, 'TLT')\n",
    "    df_debt_return, df_debt_value = computeReturns(all_debt_actions,trade, transCostRate= 0.001)\n",
    "    debt_returns, debt_stats = getStats(df_debt_return)\n",
    "    print(debt_stats)\n",
    "\n",
    "    print(\"==============All In Reit Strategy Stats===========\")\n",
    "    all_reit_actions= getTicActions(trade, 'VNQ')\n",
    "    df_reit_return, df_reit_value = computeReturns(all_reit_actions,trade, transCostRate= 0.001)\n",
    "    reit_returns, reit_stats = getStats(df_reit_return)\n",
    "    print(reit_stats)\n",
    "    \n",
    "    df_stats = pd.concat({'DRL': DRL_stats,\n",
    "                          'equalWeight': equalWeight_stats,\n",
    "                        #   'minVariance':minVariance_stats,\n",
    "                          'stock': stock_stats,\n",
    "                          'debt': debt_stats,\n",
    "                          'reit': reit_stats},axis=1)\n",
    "\n",
    "    df_annualReturn_allYear = stats_allYear(i, 'Annual return', df_stats, df_annualReturn_allYear)\n",
    "    df_mdd_allYear = stats_allYear(i, 'Max drawdown', df_stats, df_mdd_allYear)\n",
    "    df_sharpe_allYear = stats_allYear(i, 'Sharpe ratio', df_stats, df_sharpe_allYear)\n",
    "    df_sortino_allYear = stats_allYear(i, 'Sortino ratio', df_stats, df_sortino_allYear)\n",
    "    df_calmar_allYear = stats_allYear(i, 'Calmar ratio', df_stats, df_calmar_allYear)\n",
    "    \n",
    "    df_annualReturn_rank_allYear = rankCaculate(i, 'Annual return', df_stats, df_annualReturn_rank_allYear)\n",
    "    df_mdd_rank_allYear = rankCaculate(i, 'Max drawdown', df_stats, df_mdd_rank_allYear)\n",
    "    df_sharpe_rank_allYear = rankCaculate(i, 'Sharpe ratio', df_stats, df_sharpe_rank_allYear)\n",
    "    df_sortino_rank_allYear = rankCaculate(i, 'Sortino ratio', df_stats, df_sortino_rank_allYear)\n",
    "    df_calmar_rank_allYear = rankCaculate(i, 'Calmar ratio', df_stats, df_calmar_rank_allYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_allYear(df_annualReturn_allYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_allYear(df_mdd_allYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_allYear(df_calmar_allYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_allYear(df_sharpe_allYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_allYear(df_sortino_allYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annualReturn_rank_allYear_avg = average_allYear(df_annualReturn_rank_allYear)\n",
    "df_annualReturn_rank_allYear_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mdd_rank_allYear_avg  = average_allYear(df_mdd_rank_allYear)\n",
    "df_mdd_rank_allYear_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharpe_rank_allYear_avg = average_allYear(df_sharpe_rank_allYear)\n",
    "df_sharpe_rank_allYear_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sortino_rank_allYear_avg = average_allYear(df_sortino_rank_allYear)\n",
    "df_sortino_rank_allYear_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calmar_rank_allYear_avg = average_allYear(df_calmar_rank_allYear)\n",
    "df_calmar_rank_allYear_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2d2e8e450be3e223dc413b7f8a28490ca56561e6968625b0b65da592ce3e9cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('FinRL': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
